import os
import boto3
from botocore.exceptions import NoCredentialsError, ClientError
import mlflow
import mlflow.sklearn
import shutil
from typing import Type
from pydantic import BaseModel, create_model
import streamlit as st
import pandas as pd
import numpy as np
import shap
import altair as alt
import seaborn as sns
import matplotlib.pyplot as plt
import joblib
from googletrans import Translator
import asyncio
from dotenv import load_dotenv

def get_s3_file(bucket_name, s3_path, local_path):
    """
    TÃ©lÃ©charge un fichier depuis S3 et le sauvegarde localement.
    """
    os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'https://s3.amazonaws.com'
    load_dotenv()
    # Access AWS credentials from environment variables
    os.environ['AWS_ACCESS_KEY_ID'] = os.environ.get('ACCESS_KEY')
    os.environ['AWS_SECRET_ACCESS_KEY'] = os.environ.get('SECRET_KEY')
    os.environ['AWS_DEFAULT_REGION'] = os.environ.get('AWS_DEFAULT_REGION', 'eu-north-1')
    s3_client = boto3.client(
        's3',
        aws_access_key_id=os.environ['AWS_ACCESS_KEY_ID'],
        aws_secret_access_key=os.environ['AWS_SECRET_ACCESS_KEY'],
        region_name=os.environ['AWS_DEFAULT_REGION']
    )

    if not os.path.exists(os.path.dirname(local_path)):
        os.makedirs(os.path.dirname(local_path))
    try:
        # Download the file from S3
        filename = os.path.basename(s3_path)
        for file in s3_client.list_objects_v2(Bucket=bucket_name, Prefix=s3_path).get('Contents', []):
            if file['Key'] == s3_path:
                try:
                    s3_client.download_file(bucket_name, file['Key'], local_path)
                    print(f"Fichier tÃ©lÃ©chargÃ© avec succÃ¨s depuis s3://{bucket_name}/{s3_path} vers {local_path}")
                except ClientError as e:
                    print(f"Erreur lors du tÃ©lÃ©chargement du fichier: {e}")
    except NoCredentialsError:
        print("Erreur: Les identifiants AWS ne sont pas disponibles.")
    except ClientError as e:
        print(f"Erreur lors de l'accÃ¨s Ã  S3: {e}")
        if "AccessDenied" in str(e):
            print("AccÃ¨s au bucket refusÃ©. VÃ©rifiez vos permissions.")
            print("Suggestions:")
            print("1. VÃ©rifiez que le nom du bucket est correct")
            print("2. VÃ©rifiez que vous avez les permissions suivantes:")
            print("   - s3:GetObject")
            print("   - s3:ListBucket")
            print("3. VÃ©rifiez que vos clÃ©s d'accÃ¨s AWS sont valides")
            print("4. VÃ©rifiez que la rÃ©gion est correcte")

def get_s3_csv(bucket_name, s3_path, local_path, encoding, sep):
        """
        TÃ©lÃ©charge un fichier CSV depuis S3 et le sauvegarde localement.
        """
        try:
            # Download the file from S3
            get_s3_file(bucket_name, s3_path, local_path)
            print(f"Fichier tÃ©lÃ©chargÃ© avec succÃ¨s depuis s3://{bucket_name}/{s3_path} vers {local_path}")
            # Read the CSV file
            df = pd.read_csv(local_path, sep=sep, encoding=encoding)
            return df
        except NoCredentialsError:
            print("Erreur: Les identifiants AWS ne sont pas disponibles.")
        except ClientError as e:
            print(f"Erreur lors de l'accÃ¨s Ã  S3: {e}")
            if "AccessDenied" in str(e):
                print("AccÃ¨s au bucket refusÃ©. VÃ©rifiez vos permissions.")
                print("Suggestions:")
                print("1. VÃ©rifiez que le nom du bucket est correct")
                print("2. VÃ©rifiez que vous avez les permissions suivantes:")
                print("   - s3:GetObject")
                print("   - s3:ListBucket")
                print("3. VÃ©rifiez que vos clÃ©s d'accÃ¨s AWS sont valides")
                print("4. VÃ©rifiez que la rÃ©gion est correcte")

class Utils:

    def __init__(self):
        pass


    @staticmethod
    def case_when(*args):
        """
        Fonction pour crÃ©er une colonne avec des conditions.
        """
        if len(args) % 2 != 0:
            raise ValueError("Le nombre d'arguments doit Ãªtre pair.")
        conditions = args[::2]
        values = args[1::2]
        return np.select(conditions, values, default=None)

    @staticmethod
    def load_model_from_s3():
        """"
        Va chercher le modÃ¨le depuis le bucket S3, le tÃ©lÃ©charge et le charge.
        """
        load_dotenv()
        # Configure AWS S3 settings
        os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'https://s3.amazonaws.com'
        # Load environment variables from .env file
        load_dotenv()
        
        # Access AWS credentials from environment variables
        os.environ['AWS_ACCESS_KEY_ID'] = os.environ.get('ACCESS_KEY')
        os.environ['AWS_SECRET_ACCESS_KEY'] = os.environ.get('SECRET_KEY')
        os.environ['AWS_DEFAULT_REGION'] = os.environ.get('AWS_DEFAULT_REGION', 'eu-north-1')

        # Define S3 bucket and key
        bucket_name = 'projet-7-opc'
        s3_prefix = 'models/my-model'
        local_model_path = './Data/Modele/'

        # modele
        if st.session_state.get('model') == None:

            try:
                # Initialize S3 client
                s3_client = boto3.client(
                    's3',
                    aws_access_key_id=os.environ['AWS_ACCESS_KEY_ID'],
                    aws_secret_access_key=os.environ['AWS_SECRET_ACCESS_KEY'],
                    region_name=os.environ['AWS_DEFAULT_REGION']
                )
                
                # Test access to the bucket
                print(f"Test de l'accÃ¨s au bucket: {bucket_name}")
                try:
                    s3_client.list_objects_v2(Bucket=bucket_name, MaxKeys=1)
                    print(f"AccÃ¨s au bucket: {bucket_name} confirmÃ©")
                except ClientError as e:
                    print(f"Erreur lors de la tentative d'accÃ¨s au bucket {bucket_name}: {e}")
                    print("VÃ©rifiez que le nom du bucket est correct et que vous avez les permissions nÃ©cessaires.")
                    raise
                
                # Create a local directory to store the downloaded model
                if os.path.exists(local_model_path):
                    shutil.rmtree(local_model_path)  # Remove if exists
                os.makedirs(local_model_path)
                
                # List all objects under the s3_prefix
                response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=s3_prefix)
                
                if 'Contents' not in response:
                    print(f"Rien trouvÃ© dans s3://{bucket_name}/{s3_prefix}")
                    exit(1)
                
                # Download each file from S3
                for item in response['Contents']:
                    s3_key = item['Key']
                    # Create local path maintaining folder structure
                    relative_path = s3_key.replace(s3_prefix + '/', '')
                    local_file_path = os.path.join(local_model_path, relative_path)
                    
                    # Ensure directory exists
                    os.makedirs(os.path.dirname(local_file_path), exist_ok=True)
                    
                    print(f"TÃ©lÃ©chargement de s3://{bucket_name}/{s3_key} vers {local_file_path}")
                    s3_client.download_file(bucket_name, s3_key, local_file_path)
                
                print(f"ModÃ¨le tÃ©lÃ©chargÃ© avec succÃ¨s dans {local_model_path}")
                
                # Load the model
                model = mlflow.sklearn.load_model(local_model_path)
                st.session_state.model = model

                if st.session_state.get('model') is None:
                    raise ValueError("Le modÃ¨le n'a pas pu Ãªtre chargÃ©.")
                
                print("Model loaded successfully!")
                
            except NoCredentialsError:
                print("AWS credentials not found or invalid")
            except ClientError as e:
                print(f"AWS S3 error: {e}")
                if "AccessDenied" in str(e):
                    print("AccÃ¨s au bucket refusÃ©. VÃ©rifiez vos permissions.")
                    print("Suggestions:")
                    print("1. VÃ©rifiez que le nom du bucket est correct")
                    print("2. VÃ©rifiez que vous avez les permissions suivantes:")
                    print("   - s3:GetObject")
                    print("   - s3:ListBucket")
                    print("3. VÃ©rifiez que vos clÃ©s d'accÃ¨s AWS sont valides")
                    print("4. VÃ©rifiez que la rÃ©gion est correcte")
            except Exception as e:
                print(f"Error: {e}")
        else:
            print("Utilisation du modÃ¨le mise en cache.")
        return None

    @staticmethod
    def create_feature_model(path: str = './Data/Prep/feature_names.csv', sep:str = ';', encoding:str = 'utf-8') -> Type[BaseModel]:
        df = get_s3_csv(
            bucket_name='projet-7-opc',
            s3_path='data/Data/Prep/feature_names.csv',
            local_path=path,
            encoding=encoding,
            sep=sep
        )
        df = df.dropna()
        fields = {}
        for _, row in df.iterrows():
            feature_name = row['features']
            feature_type = row['type']
            if feature_type.startswith('int'):
                fields[feature_name] = (int, ...)
            elif feature_type.startswith('float'):
                fields[feature_name] = (float, ...)
            else:
                fields[feature_name] = (str, ...)
        feature_model = create_model('FeatureModel', **fields)
        st.session_state.feature_model = feature_model
        return None

    @staticmethod
    def init_feature_names(path: str = './Data/Prep/feature_names.csv', sep:str = ';', encoding:str = 'utf-8') -> list:
        df = get_s3_csv(
            bucket_name='projet-7-opc',
            s3_path='data/Data/Prep/feature_names.csv',
            local_path=path,
            encoding=encoding,
            sep=sep
        )
        df = df.dropna()
        feature_names = df['features'].tolist()
        st.session_state.feature_names = feature_names
        return None

    @staticmethod
    def get_columns_descriptions(path: str = './Data/Prep/HomeCredit_columns_description.csv', sep:str = ',', encoding:str = 'utf-8') -> dict:
        """
        Charge les descriptions des colonnes depuis un fichier CSV.
        """
        df = get_s3_csv(
            bucket_name='projet-7-opc',
            s3_path='data/Data/Prep/HomeCredit_columns_description.csv',
            local_path=path,
            encoding=encoding,
            sep=sep
        )
        df = df.loc[:, ['Row', 'Description']]
        df.rename(columns={'Row': 'Features', 'Description': 'Description'}, inplace=True)
        st.session_state.columns_descriptions = df
        return None

    @staticmethod
    def init_shap_explainer(model):
        """
        Initialise l'explainer SHAP pour le modÃ¨le donnÃ©.
        """
        if model is None:
            raise ValueError("Le modÃ¨le est None. Veuillez charger un modÃ¨le valide.")
        
        # On utilise le modÃ¨le pour crÃ©er un explainer SHAP
        explainer = shap.Explainer(model)
        tree_explainer = shap.TreeExplainer(model)
        st.session_state.explainer = explainer
        st.session_state.tree_explainer = tree_explainer
        return None
    
    @staticmethod
    def get_shap_values(explainer, data, n_sample:int = 1000):
        """
        Calcule les valeurs SHAP pour un Ã©chantillon de donnÃ©es donnÃ©.
        """
        if explainer is None:
            raise ValueError("L'explainer SHAP est None. Veuillez initialiser l'explainer.")
        
        with st.spinner("Calcul des valeurs SHAP...", show_time=True):
            # On utilise l'explainer pour calculer les valeurs SHAP
            shap_values = explainer(data.sample(n=n_sample, random_state=42))
            st.session_state.shap_values = shap_values
        return None

    @staticmethod
    def load_data(feature_list: list = None):
        """
        Charge les donnÃ©es

        Args:
            feature_list (list): Liste des features Ã  charger.
        """
        root_path = 'data/Data/Input_data/'
        train = [
            'X_train.csv',
            'train_ids.csv',
            'y_train.csv',
        ]

        test = [
            'X_test.csv',
            'test_ids.csv',
            'y_test.csv',
        ]
        download_root_path = './Data/Input_data/'
        if not os.path.exists(download_root_path):
            os.makedirs(download_root_path)

        # On charge les donnÃ©es d'entrainement
        train_data = get_s3_csv(
            bucket_name='projet-7-opc',
            s3_path='data/Data/Input_data/X_train.csv',
            local_path='./Data/Input_data/X_train.csv',
            encoding='utf-8',
            sep=';'
        )

        train_ids = get_s3_csv(
            bucket_name='projet-7-opc',
            s3_path=os.path.join(root_path, train[1]),
            local_path=os.path.join(download_root_path, train[1]),
            encoding='utf-8',
            sep=';'
        )
        train_data['SK_ID_CURR'] = train_ids['SK_ID_CURR']

        # On charge les donnÃ©es de test
        test_data = get_s3_csv(
            bucket_name='projet-7-opc',
            s3_path=os.path.join(root_path, test[0]),
            local_path=os.path.join(download_root_path, test[0]),
            encoding='utf-8',
            sep=';'
        )
        test_ids = get_s3_csv(
            bucket_name='projet-7-opc',
            s3_path=os.path.join(root_path, test[1]),
            local_path=os.path.join(download_root_path, test[1]),
            encoding='utf-8',
            sep=';'
        )
        test_data['SK_ID_CURR'] = test_ids['SK_ID_CURR']

        # ConcatÃ¨ne les donnÃ©es d'entrainement et de test
        whole_data = pd.concat([train_data, test_data], axis=0, ignore_index=True)

        if feature_list is not None:
            # On ne garde que les features demandÃ©es
            whole_data = whole_data[feature_list + ['SK_ID_CURR']]

        st.session_state.data = whole_data
        st.session_state.all_ids = whole_data['SK_ID_CURR'].tolist()
        return None

    @staticmethod
    def get_raw_data():
        """
        Retourne les donnÃ©es brutes.
        """
        paths = [
            'data/Data/Input_data/application_train.csv',
            'data/Data/Input_data/application_test.csv'
        ]

        data = pd.DataFrame()
        for path in paths:
            df = get_s3_csv(
                bucket_name='projet-7-opc',
                s3_path=path,
                local_path='./Data/Input_data/' + os.path.basename(path),
                encoding='utf-8',
                sep=','
            )
            data = pd.concat([data, df], axis=0, ignore_index=True)
        data = data.loc[data['SK_ID_CURR'].isin(st.session_state.all_ids), :]
        st.session_state.raw_data = data
        return None

    @staticmethod
    def get_model_features(model):
        """
        Retourne les features du modÃ¨le donnÃ©.
        """
        if model is None:
            raise ValueError("Le modÃ¨le est None. Veuillez charger un modÃ¨le valide.")
        
        # On utilise le modÃ¨le pour obtenir les features
        feature_names = model.get_feature_names_out()
        st.session_state.feature_names = feature_names
        return None

    @staticmethod
    def run_model(model, data):
        """
        ExÃ©cute le modÃ¨le sur les donnÃ©es fournies et retourne les prÃ©dictions ainsi que leur probabilitÃ©.
        """
        if model is None:
            raise ValueError("Le modÃ¨le est None. Veuillez charger un modÃ¨le valide.")
        
        if 'SK_ID_CURR' in data.columns:
            data = data.drop(columns=['SK_ID_CURR'])
        
        # On utilise le modÃ¨le pour faire des prÃ©dictions
        predictions = model.predict(data)
        probabilities = model.predict_proba(data)[:, 1]
        st.session_state.predictions = predictions
        st.session_state.probabilities = probabilities
        return None

    @staticmethod
    def load_pretraitement():
        """
        Charge le scaler pour les donnÃ©es.
        """
        # Get joblib files from S3
        paths = [
            'data/Data/Prep/cat_imputer.joblib',
            'data/Data/Prep/num_imputer.joblib',
            'data/Data/Prep/scaler.joblib',
            'data/Data/Prep/onehot.joblib'
        ]

        for path in paths:
            get_s3_file(
                bucket_name='projet-7-opc',
                s3_path=path,
                local_path='./Data/Prep/' + os.path.basename(path)
            )

        cat_imputer = joblib.load('./Data/Prep/cat_imputer.joblib')
        num_imputer = joblib.load('./Data/Prep/num_imputer.joblib')
        scaler = joblib.load('./Data/Prep/scaler.joblib')
        onehot = joblib.load('./Data/Prep/onehot.joblib')
        st.session_state.cat_imputer = cat_imputer
        st.session_state.num_imputer = num_imputer
        st.session_state.scaler = scaler
        st.session_state.onehot = onehot
        return None

def init_session_state_variables():
    """
    Initialise les variables de session pour Streamlit.
    """
    if st.session_state.get('init_done') is None or not st.session_state.get('init_done'):
        st.title("Initialisation des variables de session")
        st.write("Veuillez patienter et ne pas recharger la page. Cette opÃ©ration ne se fait qu'une seule fois.")
        progress_bar = st.progress(0, text="Initialisation en cours...")
        step_number = 7
        # 1 - ModÃ¨le S3
        if st.session_state.get('model') is None:
            Utils.load_model_from_s3()
            progress_bar.progress(
                (1 / step_number)
            )
        # Features
            # 2 - FeatureModel
        if st.session_state.get('feature_model') is None:
            Utils.create_feature_model()
            progress_bar.progress(
                (2 / step_number)
            )
            # 3 - Feature names
        if st.session_state.get('feature_names') is None:
            Utils.init_feature_names()
            progress_bar.progress(
                (3 / step_number)
            )
            # 4 - Descriptions des colonnes
        if st.session_state.get('columns_descriptions') is None:
            Utils.get_columns_descriptions()
            progress_bar.progress(
                (4 / step_number)
            )
        # 5 - DonnÃ©es
        if st.session_state.get('data') is None:
            Utils.load_data(
                feature_list=st.session_state.get('feature_names')
            )
            Utils.get_raw_data()
            Utils.load_pretraitement()
            progress_bar.progress(
                (5 / step_number)
            )
        # 6 - PrÃ©dictions/ProbabilitÃ©s
        if (st.session_state.get('predictions') is None) or (st.session_state.get('probabilities') is None):
            Utils.run_model(
                model=st.session_state.get('model'), 
                data=st.session_state.get('data')
            )
            progress_bar.progress(
                (6 / step_number)
            )
        # 7 - SHAP values
        if st.session_state.get('shap_values') is None:
            Utils.init_shap_explainer(st.session_state.get('model'))
            progress_bar.progress(
                (7 / step_number)
            )
        st.success("Initialisation terminÃ©e ! Vous pouvez maintenant utiliser le tableau de bord.")
        st.session_state['init_done'] = True
    return None

def prediction():

    st.title("PrÃ©diction")
    # Afficher la classe prÃ©dite
    st.subheader(f"Classe prÃ©dite pour le client nÂ°{st.session_state.id_client}")
    predictions = st.session_state.get('predictions')[st.session_state.index_client]
    probabilites = st.session_state.get('probabilities')[st.session_state.index_client]
    client_prediction = int(predictions)
    client_probability = float(probabilites)
    solvabiliy_rate = 100 * client_probability
    cutoff_threshold = 0.5
    st.metric(
        label="ProbabilitÃ© de solvabilitÃ©",
        value=f"{solvabiliy_rate:.2f}%",
        delta=f"{100*(client_probability - cutoff_threshold):.2f}%",
        delta_color="normal",
        help="ProbabilitÃ© que le client soit solvable, ie qu'il rembourse son prÃªt, dÃ©terminÃ©e par le modÃ¨le de Machine Learning. \
            La probabilitÃ© est calculÃ©e en fonction des caractÃ©ristiques du client et de l'algorithme de Machine Learning utilisÃ©. \
                **La flÃ¨che indique si la probabilitÃ© est supÃ©rieure ou infÃ©rieure au seuil de dÃ©cision, fixÃ© Ã  50% par dÃ©faut. \
                Si la probabilitÃ© est supÃ©rieure au seuil, le client est considÃ©rÃ© comme solvable.**"
    )
    human_readable_prediction = "Non solvable" if client_prediction == 0 else "Solvable"
    if human_readable_prediction == "Solvable":
        st.success(f"Le modÃ¨le prÃ©dit que le client nÂ°{st.session_state.id_client} est **{human_readable_prediction}**.")
    else:
        st.error(f"Le modÃ¨le prÃ©dit que le client nÂ°{st.session_state.id_client} est **{human_readable_prediction}**.")


    # Afficher les shap values principales expliquant la prÃ©diction
    st.subheader(f"Raisons du score pour le client nÂ°{st.session_state.id_client}", 
                 help="Valeurs SHAP pour le client sÃ©lectionnÃ©. \
                    Les valeurs SHAP indiquent l'importance de chaque caractÃ©ristique client dans la prÃ©diction du modÃ¨le. \
                    Les valeurs positives indiquent que la caractÃ©ristique contribue Ã  augmenter la probabilitÃ© de solvabilitÃ©, \
                    tandis que les valeurs nÃ©gatives indiquent une contribution Ã  diminuer cette probabilitÃ©. \
                    Cette contribution (positive comme nÃ©gative) est d'autant plus marquÃ©e que la valeur est Ã©levÃ©e.")
    st.radio(
        label="Mode d'affichage des valeurs SHAP",
        options=['RÃ©duit', 'Complet'],
        index=0,
        key='shap_mode',
        on_change=lambda: st.session_state.update({'mode': st.session_state.shap_mode.lower()}),
        help="Mode d'affichage des valeurs SHAP. \
        Le mode 'RÃ©duit' affiche uniquement les caractÃ©ristiques les plus importantes, \
        tandis que le mode 'Complet' affiche toutes les caractÃ©ristiques."
    )
    explainer = st.session_state.get('explainer')
    client_data_for_shap = st.session_state.get('data').drop(columns=['SK_ID_CURR']).iloc[st.session_state.index_client:st.session_state.index_client+1]
    
    individual_shap_values = explainer(client_data_for_shap)
    
    def get_shap_df(values = individual_shap_values, mode:str = 'rÃ©duit'):
        """
        Fonction pour obtenir le DataFrame des valeurs SHAP.
        """

        # We select shap values for class 1: individual_shap_values.values[0, :, 1]
        shap_values_for_class_1 = individual_shap_values.values[0, :, 1]
        shap_df = pd.DataFrame({
            'Feature': client_data_for_shap.columns,
            'SHAP Value': shap_values_for_class_1
        })
        shap_df = shap_df.sort_values(by='SHAP Value', ascending=False)

        if mode == 'rÃ©duit':
            # Garder les features qui portent sont dans le top 75% (en valeur absolue, et en termes de quantiles) des valeurs SHAP
            q95 = shap_df['SHAP Value'].abs().quantile(0.95)
            shap_df['To display'] = Utils.case_when(
                shap_df['SHAP Value'].abs() > q95, True,
                shap_df['SHAP Value'].abs() < q95, False
            )
            new_df = pd.DataFrame({
                'Feature' : ['Autres impacts positifs', 'Autres impacts nÃ©gatifs'],
                'SHAP Value' : [0, 0]
            })
            # On garde les features qui portent sont dans le top 75% (en valeur absolue, et en termes de quantiles) des valeurs SHAP
            # Le reste est mis dans des "Autres impacts positifs" ou "Autres impacts nÃ©gatifs" condensÃ©s
            for i, row in shap_df.iterrows():
                if row['To display']:
                    new_df = pd.concat([new_df, row.to_frame().T], ignore_index=True)
                else:
                    if row['SHAP Value'] > 0:
                        new_df.loc[new_df['Feature'] == 'Autres impacts positifs', 'SHAP Value'] += row['SHAP Value']
                    else:
                        new_df.loc[new_df['Feature'] == 'Autres impacts nÃ©gatifs', 'SHAP Value'] += row['SHAP Value']
        
        if mode == 'complet':
            # Garder toutes les features
            new_df = shap_df.copy()

        # Rajouter la colonne de valeur absolue si pas dÃ©jÃ  prÃ©sente
        new_df['Abs SHAP Value'] = new_df['SHAP Value'].abs()
        # Trier le DataFrame par valeur absolue dÃ©croissante
        new_df = new_df.sort_values(by='Abs SHAP Value', ascending=False)
        # RÃ©initialiser l'index
        new_df.reset_index(drop=True, inplace=True)
        return new_df

    # Initialiser le mode
    if 'mode' not in st.session_state:
        st.session_state.mode = 'rÃ©duit'

    def get_chart(shap_df):
        chart = alt.Chart(get_shap_df(mode=st.session_state.mode)).mark_bar().encode(
            x='SHAP Value', # Valeur SHAP
            y=alt.Y('Feature', sort=alt.EncodingSortField(field="Abs SHAP Value", op="sum", order='descending')), # Nom de la feature + tri par valeur SHAP dÃ©croissant
            color=alt.condition(
                alt.datum['SHAP Value'] > 0, # Condition pour la couleur
                alt.value('green'),
                alt.value('red')
            ), # Couleur en fonction de la valeur SHAP : bleu si positive, rouge si nÃ©gative
            tooltip=['Feature', 'SHAP Value'] # Info-bulle avec le nom de la feature et la valeur SHAP
        ).properties(
            title='Importance des caractÃ©ristiques (Valeurs SHAP)' # Titre du graphique
        )
        return chart
    st.altair_chart(get_chart(get_shap_df(mode=st.session_state.mode)), 
                    use_container_width=True)

def positionnement():
    st.title("Positionnement du client par rapport Ã  la population")
    
    nb_clients = st.session_state.get('data').shape[0]
    nb_clients_solvables = np.sum(st.session_state.get('predictions'))
    col1, col2 = st.columns(2)
    with col1:
        st.metric(
            label="Nombre total de clients dans la population",
            value=nb_clients,
            delta_color="normal",
            help="Nombre total de clients dans la population. \
                Cette valeur est calculÃ©e en comptant le nombre de lignes dans le DataFrame des donnÃ©es."
        )
    with col2:
        st.metric(
            label="Part de clients prÃ©dits solvables dans la population",
            value=f"{(nb_clients_solvables / nb_clients) * 100:.1f}%",
            delta_color="normal",
            help="Part de clients prÃ©dits solvables dans la population. \
                Cette valeur est calculÃ©e en divisant le nombre de clients solvables par le nombre total de clients dans la population."
        )
    client_prediction = st.session_state.get('predictions')[st.session_state.index_client]
    human_readable_prediction = "Non solvable" if client_prediction == 0 else "Solvable"
    if human_readable_prediction == "Solvable":
        st.success(f"Le modÃ¨le prÃ©dit que le client nÂ°{st.session_state.id_client} est **{human_readable_prediction}**.")
    else:
        st.error(f"Le modÃ¨le prÃ©dit que le client nÂ°{st.session_state.id_client} est **{human_readable_prediction}**.")

    if not st.session_state.get('init_done') or not st.session_state.get('id_client'):
        st.warning("Les donnÃ©es ne sont pas initialisÃ©es ou aucun client n'est sÃ©lectionnÃ©. Veuillez attendre la fin de l'initialisation et sÃ©lectionner un client dans la barre latÃ©rale.")
        return
    
    explainer = st.session_state.get('explainer')
    client_data_for_shap = st.session_state.get('data').drop(columns=['SK_ID_CURR']).iloc[st.session_state.index_client:st.session_state.index_client+1]
    
    individual_shap_values = explainer(client_data_for_shap)
    
    def get_shap_df(values = individual_shap_values, mode:str = 'rÃ©duit'):
        """
        Fonction pour obtenir le DataFrame des valeurs SHAP.
        """

        # We select shap values for class 1: individual_shap_values.values[0, :, 1]
        shap_values_for_class_1 = individual_shap_values.values[0, :, 1]
        shap_df = pd.DataFrame({
            'Feature': client_data_for_shap.columns,
            'SHAP Value': shap_values_for_class_1
        })
        shap_df['Abs SHAP Value'] = shap_df['SHAP Value'].abs()
        shap_df = shap_df.sort_values(by='Abs SHAP Value', ascending=False)
        shap_df.drop(columns=['Abs SHAP Value'], inplace=True)
        st.session_state['top_shap_features'] = shap_df
        return None
    # On appelle la fonction pour trier les features par valeur SHAP dÃ©croissante
    with st.spinner("Calcul des valeurs SHAP pour la population...", show_time=True):
        get_shap_df()

    def reverse_pretreatment(data):
        """
        Fonction pour dÃ©normaliser les donnÃ©es.
        """
        # On inverse le prÃ©traitement des donnÃ©es
        cat_imputer = st.session_state.get('cat_imputer')
        num_imputer = st.session_state.get('num_imputer')
        scaler = st.session_state.get('scaler')
        onehot = st.session_state.get('onehot')

        if scaler is not None:
            # Get all feature names the scaler was fitted on
            all_fitted_scaler_features = scaler.get_feature_names_out()
            # Identify features that are in the current data AND were handled by this scaler
            features_to_transform = [col for col in all_fitted_scaler_features if col in data.columns]
            
            if features_to_transform:
                # Perform manual inverse transformation for each relevant column
                for col_name in features_to_transform:
                    try:
                        # Find the index of the current column in the scaler's list of all fitted features
                        idx_in_scaler = list(all_fitted_scaler_features).index(col_name)
                        
                        # Apply inverse transformation: X_original = (X_scaled * scale) + mean
                        # Ensure scaler.scale_ and scaler.mean_ are accessed with the correct index
                        if hasattr(scaler, 'scale_') and scaler.scale_ is not None and \
                           hasattr(scaler, 'mean_') and scaler.mean_ is not None and \
                           hasattr(scaler, 'with_std') and scaler.with_std and \
                           hasattr(scaler, 'with_mean') and scaler.with_mean:
                            data[col_name] = data[col_name] * scaler.scale_[idx_in_scaler] + scaler.mean_[idx_in_scaler]
                        elif hasattr(scaler, 'scale_') and scaler.scale_ is not None and \
                             hasattr(scaler, 'with_std') and scaler.with_std: # and not scaler.with_mean (or mean_ is None)
                            data[col_name] = data[col_name] * scaler.scale_[idx_in_scaler]
                        elif hasattr(scaler, 'mean_') and scaler.mean_ is not None and \
                             hasattr(scaler, 'with_mean') and scaler.with_mean: # and not scaler.with_std (or scale_ is None, centering only)
                            data[col_name] = data[col_name] + scaler.mean_[idx_in_scaler]
                        # If neither with_std nor with_mean, or scale_/mean_ are None, no transformation was effectively done by the scaler for this feature.
                        
                    except ValueError:
                        # This case should ideally not be reached if features_to_transform is built correctly
                        st.warning(f"Colonne {col_name} prÃ©vue pour la dÃ©normalisation mais non trouvÃ©e dans les caractÃ©ristiques du scaler.")
                    except IndexError:
                        st.error(f"Erreur d'index pour la colonne {col_name} lors de la dÃ©normalisation. "
                                 f"Index: {idx_in_scaler}, Taille de scale/mean: {len(scaler.scale_ if hasattr(scaler, 'scale_') and scaler.scale_ is not None else scaler.mean_)}")
        return data
    
    st.session_state['unscaled_data'] = reverse_pretreatment(st.session_state.get('data').drop(columns=['SK_ID_CURR']))

    st.subheader("Analyse univariÃ©e du positionnement du client par rapport Ã  la population",
                 help="Permet de comparer la valeur client sur une caractÃ©ristique donnÃ©e par rapport au reste de la clientÃ¨le.")
    st.selectbox(
        label="SÃ©lectionnez une caractÃ©ristique",
        options=st.session_state.get('top_shap_features')['Feature'].tolist(),
        index=st.session_state.get('top_shap_features')['Feature'].tolist().index(st.session_state.get('feature_selection')) if st.session_state.get('feature_selection') in st.session_state.get('top_shap_features')['Feature'].tolist() else 0,
        key='feature_selection',
        help="SÃ©lectionnez une caractÃ©ristique pour voir son impact sur la prÃ©diction du client sÃ©lectionnÃ©. \
            Les caractÃ©ristiques sont triÃ©es par valeur SHAP dÃ©croissante pour toute la population. \
                Les valeurs SHAP indiquent l'importance de chaque caractÃ©ristique client dans la prÃ©diction du modÃ¨le."
    )

    feature = st.session_state.get('feature_selection')
    if 'graph_mode' not in st.session_state:
        st.session_state.graph_mode = 'histogramme'

    st.radio(
        label="Mode d'affichage",
        options=['histogramme', 'boxplot'],
        format_func=str.capitalize,
        index=0,
        key='graph_mode',
        help="Mode d'affichage des valeurs SHAP. \
        Le mode 'Histogramme' affiche un histogramme de la distribution de la caractÃ©ristique, \
        tandis que le mode 'Boxplot' affiche un boxplot de la distribution de la caractÃ©ristique."
    )

    # DÃ©terminer si la caractÃ©ristique sÃ©lectionnÃ©e a un impact positif ou nÃ©gatif sur la prÃ©diction du client
    if feature in st.session_state.get('top_shap_features')['Feature'].tolist():
        feature_shap_value = st.session_state.get('top_shap_features').loc[st.session_state.get('top_shap_features')['Feature'] == feature, 'SHAP Value'].values[0]
        if feature_shap_value > 0:
            st.success(f"La caractÃ©ristique {feature} a un impact positif sur la prÃ©diction du client nÂ°{st.session_state.id_client}.")
        else:
            st.error(f"La caractÃ©ristique {feature} a un impact nÃ©gatif sur la prÃ©diction du client nÂ°{st.session_state.id_client}.")

    if not feature:
        st.warning("Veuillez sÃ©lectionner une caractÃ©ristique.")
        return

    # Afficher la distribution de la caractÃ©ristique sÃ©lectionnÃ©e en affichant le positionnement du client avec une ligne rouge
    st.subheader(f"Positionnement du client nÂ°{st.session_state.id_client} sur la caractÃ©ristique {feature}",
                 help="Distribution de la caractÃ©ristique sÃ©lectionnÃ©e pour toute la population. \
                    Le client sÃ©lectionnÃ© est reprÃ©sentÃ© par une ligne rouge.")
    # On rÃ©cupÃ¨re la valeur de la caractÃ©ristique pour le client sÃ©lectionnÃ©
    client_value = st.session_state.get('unscaled_data').loc[st.session_state.get('data')['SK_ID_CURR'] == st.session_state.id_client, feature].values[0]
    # On rÃ©cupÃ¨re la distribution de la caractÃ©ristique pour toute la population
    population_values = st.session_state.get('unscaled_data')[feature].values
    # On crÃ©e un DataFrame avec la distribution de la caractÃ©ristique
    population_df = pd.DataFrame({
        'CaractÃ©ristique': population_values
    })
    def get_distribution_chart(mode):
        """
        Fonction pour crÃ©er le graphique de distribution de la caractÃ©ristique sÃ©lectionnÃ©e.
        """
        if mode == 'histogramme':
            # On crÃ©e un histogramme de la distribution de la caractÃ©ristique avec Altair
            chart = alt.Chart(population_df).mark_bar().encode(
                x=alt.X('CaractÃ©ristique', bin=alt.Bin(maxbins=20), title=feature), # Histogramme avec 20 bins
                y=alt.Y('count()', title='Nombre de clients'), # Nombre de clients
                tooltip=['count()'] # Info-bulle avec le nombre de clients
            ).properties(
            )
            # On ajoute une ligne rouge pour le client sÃ©lectionnÃ©
            chart += alt.Chart(pd.DataFrame({'CaractÃ©ristique': [client_value]})).mark_rule(color='red').encode(
                x='CaractÃ©ristique:Q', # Valeur de la caractÃ©ristique pour le client sÃ©lectionnÃ©
                tooltip=['CaractÃ©ristique'] # Info-bulle avec la valeur de la caractÃ©ristique
            ).properties()
        elif mode == 'boxplot':
            # On crÃ©e un boxplot de la distribution de la caractÃ©ristique avec Altair
            chart = alt.Chart(population_df).mark_boxplot(extent='min-max').encode(
                y=alt.Y('CaractÃ©ristique:Q', title=feature), # Boxplot
                tooltip=[alt.Tooltip('CaractÃ©ristique:Q', title=feature)]
            ).properties(
                title=f"Distribution de la caractÃ©ristique {feature} pour toute la population", # Titre du graphique
                width=300 
            )
            # On ajoute une ligne rouge pour le client sÃ©lectionnÃ©
            client_line = alt.Chart(pd.DataFrame({'CaractÃ©ristique': [client_value]})).mark_rule(color='red', size=2).encode(
                y='CaractÃ©ristique:Q',
                tooltip=[alt.Tooltip('CaractÃ©ristique:Q', title=f"Valeur client ({st.session_state.id_client})")]
            )
            chart = chart + client_line
        return chart
    # On appelle la fonction pour crÃ©er le graphique de distribution de la feature sÃ©lectionnÃ©e
    with st.spinner("Calcul de la distribution de la caractÃ©ristique...", show_time=True):
        st.altair_chart(get_distribution_chart(st.session_state.get('graph_mode')), use_container_width=True)
    mean_value = st.session_state.get('unscaled_data')[feature].mean()
    std_value = st.session_state.get('unscaled_data')[feature].std()
    client_value = st.session_state.get('unscaled_data').loc[st.session_state.get('data')['SK_ID_CURR'] == st.session_state.id_client, feature].values[0]
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(
            label=f"Valeur du client nÂ°{st.session_state.id_client}",
            value=f"{client_value:.2f}",
            help="Valeur de la caractÃ©ristique pour le client sÃ©lectionnÃ©. \
                Cette valeur est calculÃ©e en prenant la valeur de la caractÃ©ristique pour le client sÃ©lectionnÃ©.\
                La flÃ¨che indique si la valeur du client est supÃ©rieure ou infÃ©rieure Ã  la mÃ©diane."
        )
    with col2:
        st.metric(
            label="Moyenne de la caractÃ©ristique",
            value=f"{mean_value:.2f}",
            delta = f"{client_value - mean_value:.2f}",
            delta_color="normal",
            help="Moyenne de la caractÃ©ristique pour toute la population. \
                **La moyenne d'une sÃ©rie statistique est la somme des valeurs divisÃ©e par le nombre de valeurs. \
                On peut interprÃ©ter la moyenne comme la valeur qu'auraient toutes les valeurs si elles Ã©taient Ã©gales.**\
                La flÃ¨che indique si la valeur du client est supÃ©rieure ou infÃ©rieure Ã  la moyenne."
        )
    with col3:
        std_variation = (client_value - mean_value) / std_value
        st.metric(
            label="Ã‰cart-type de la caractÃ©ristique",
            value=f"{std_value:.2f}",
            delta = f"{std_variation:.2f}",
            delta_color="normal",
            help="Ã‰cart-type de la caractÃ©ristique pour toute la population. \
                **L'Ã©cart-type d'une sÃ©rie statistique est une mesure de la dispersion des valeurs autour de la moyenne. \
                Il indique, en moyenne, Ã  quelle distance les valeurs sont Ã©loignÃ©es de la moyenne.**\
                La flÃ¨che indique de combien de variations d'Ã©cart-type la valeur du client est Ã©loignÃ©e de la moyenne."
        )
    
    feature_description = st.session_state.get('columns_descriptions')
    print(feature)
    print(feature_description['Features'].unique())
    if feature in feature_description['Features'].unique():
        # On rÃ©cupÃ¨re la description de la caractÃ©ristique sÃ©lectionnÃ©e
        feature_description = feature_description.loc[feature_description['Features'] == feature, 'Description'].values[0]
    else:
        feature_description = "No description is available for this characteristic."    

    # Traduction de la description en franÃ§ais via Google Translate
    async def translate_text(text: str, source_language: str = 'en', target_language: str = 'fr'):
        """
        Fonction pour traduire le texte en franÃ§ais.
        """
        async with Translator() as translator:
            translated_text = await translator.translate(text, src=source_language, dest=target_language)
        # On retourne le texte traduit
        translated_text = translated_text.text
        return translated_text
    
    st.subheader(f"Description de la caractÃ©ristique {feature}",
                 help="Description de la caractÃ©ristique sÃ©lectionnÃ©e. \
                    Cette description est extraite du fichier HomeCredit_columns_description.csv. \
                    La description est traduite en franÃ§ais via Google Translate.")
    translated_text = asyncio.run(translate_text(feature_description, source_language='en', target_language='fr'))
    st.write(translated_text)

def home():
    st.title("Accueil")
    st.subheader("Bienvenue sur le tableau de bord de prÃ©diction")
    st.write("Ce tableau de bord vous permet de faire des prÃ©dictions Ã  l'aide du modÃ¨le chargÃ© depuis S3.")
    # Afficher le contenu du README.md
    with open('./README.md', 'r', encoding='utf-8') as f:
        readme_content = f.read()
    st.write(readme_content)

st.set_page_config(
    page_title="Tableau de bord de prÃ©diction",
    page_icon=":guardsman:",
    layout="wide",
    initial_sidebar_state="expanded"
)

pg = st.navigation([
    st.Page(home, title= "Accueil", icon="ðŸ "),
    st.Page(prediction, title= "PrÃ©diction", icon="ðŸ“ˆ"),
    st.Page(positionnement, title= "Positionnement", icon="ðŸ‘¤")
])

init_session_state_variables()

# Infos client sidebar
with st.sidebar:
    st.title("Informations client")
    st.write("SÃ©lectionnez un client pour voir ses informations.")
    if st.session_state.get('init_done'):
        # Id du client
        st.session_state.id_client = st.selectbox(
            label="SÃ©lectionnez l'ID du client",
            options=st.session_state.get('all_ids'),
            index=0
        )
        st.session_state.index_client = st.session_state.get('all_ids').index(st.session_state.id_client)

        client_data = st.session_state.get('raw_data').loc[st.session_state.get('raw_data')['SK_ID_CURR'] == st.session_state.id_client, :]
        gender = "Femme" if client_data['CODE_GENDER'].values[0] == 'F' else "Homme"
        how_many_children = client_data['CNT_CHILDREN'].values[0]
        adressing_client = {
            "generic": "un homme" if gender == "Homme" else "une femme",
            "pronom": "il" if gender == "Homme" else "elle",
            "children": "a un enfant" if how_many_children == 1 else (f"a {how_many_children} enfants" if how_many_children > 1 else "n'a pas d'enfants")
            }
        age = client_data['DAYS_BIRTH'].values[0] // -365
        income = client_data['AMT_INCOME_TOTAL'].values[0]
        payment_rate = client_data['AMT_CREDIT'].values[0] / client_data['AMT_ANNUITY'].values[0]
        employment_duration = client_data['DAYS_EMPLOYED'].values[0] // -30
        
        if employment_duration < 0:
            employment_duration = 0
        else:
            employment_duration = int(employment_duration)
        how_many_docs_provided = 0
        total_docs = 0
        for col in client_data.columns:
            if 'FLAG_DOCUMENT' in col:
                how_many_docs_provided += client_data[col].values[0]
                total_docs += 1
        how_many_docs_provided = int(how_many_docs_provided)
        total_docs = int(total_docs)

        st.subheader(f"Informations sur le client nÂ°{st.session_state.id_client}:")
        st.write(f"Le client nÂ°{st.session_state.id_client} est {adressing_client['generic']} de {age} ans. {adressing_client['pronom'].capitalize()} {adressing_client['children']}.")
        st.write(f"{adressing_client['pronom'].capitalize()} a un revenu de {income:.2f} $ et un taux d'endettement de {payment_rate:.2f}%.")
        st.write(f"{adressing_client['pronom'].capitalize()} a {employment_duration} mois d'anciennetÃ© dans son emploi actuel.")
        st.write(f"{adressing_client['pronom'].capitalize()} a fourni {how_many_docs_provided} document(s) sur les {total_docs} demandÃ©s.")

if __name__ == "__main__":
    pg.run()